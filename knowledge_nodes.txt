# 第0章 数学符号

## 0.1 数和数组  
- **段落摘要**：  
- **关键字**：  

## 0.2 单位矩阵与基向量  
- **段落摘要**：  
- **关键字**：  

## 0.3 随机变量  
- **段落摘要**：  
- **关键字**：  

## 0.4 集合与区间  
- **段落摘要**：  
- **关键字**：  

## 0.5 图结构  
- **段落摘要**：  
- **关键字**：  

## 0.6 索引  
- **段落摘要**：  
- **关键字**：  

## 0.7 线性代数操作  
- **段落摘要**：  
- **关键字**：  

## 0.8 微积分  
- **段落摘要**：  
- **关键字**：  

## 0.9 概率与信息论  
- **段落摘要**：  
- **关键字**：  

## 0.10 常用函数  
- **段落摘要**：  
- **关键字**：  

## 0.11 数据集与分布  
- **段落摘要**：  
- **关键字**：  


---

# 第1章 引言

## 1.1 本书面向的读者  
- **段落摘要**：  
- **关键字**：  

## 1.2 深度学习的历史趋势  
### 1.2.1 神经网络的众多名称和命运变迁  
- **段落摘要**：  
- **关键字**：  
### 1.2.2 与日俱增的数据量  
- **段落摘要**：  
- **关键字**：  
### 1.2.3 与日俱增的模型规模  
- **段落摘要**：  
- **关键字**：  
### 1.2.4 与日俱增的精度、复杂度和现实冲击  
- **段落摘要**：  
- **关键字**：  


---

# 第2章 线性代数

## 2.1 标量、向量、矩阵和张量  
- **段落摘要**：  
- **关键字**：  
## 2.2 矩阵和向量相乘  
- **段落摘要**：  
- **关键字**：  
## 2.3 单位矩阵和逆矩阵  
- **段落摘要**：  
- **关键字**：  
## 2.4 线性相关和生成子空间  
- **段落摘要**：  
- **关键字**：  
## 2.5 范数  
- **段落摘要**：  
- **关键字**：  
## 2.6 特殊类型的矩阵和向量  
- **段落摘要**：  
- **关键字**：  
## 2.7 特征分解  
- **段落摘要**：  
- **关键字**：  
## 2.8 奇异值分解  
- **段落摘要**：  
- **关键字**：  
## 2.9 Moore–Penrose 伪逆  
- **段落摘要**：  
- **关键字**：  
## 2.10 迹运算  
- **段落摘要**：  
- **关键字**：  
## 2.11 行列式  
- **段落摘要**：  
- **关键字**：  
## 2.12 实例：主成分分析  
- **段落摘要**：  
- **关键字**：  


---

# 第3章 概率与信息论

## 3.1 为什么要使用概率  
- **段落摘要**：  
- **关键字**：  
## 3.2 随机变量  
- **段落摘要**：  
- **关键字**：  
## 3.3 概率分布  
### 3.3.1 离散型变量与概率质量函数  
- **段落摘要**：  
- **关键字**：  
### 3.3.2 连续型变量与概率密度函数  
- **段落摘要**：  
- **关键字**：  
## 3.4 边缘概率  
- **段落摘要**：  
- **关键字**：  
## 3.5 条件概率  
- **段落摘要**：  
- **关键字**：  
## 3.6 链式法则  
- **段落摘要**：  
- **关键字**：  
## 3.7 独立性与条件独立性  
- **段落摘要**：  
- **关键字**：  
## 3.8 期望、方差与协方差  
- **段落摘要**：  
- **关键字**：  
## 3.9 常用概率分布  
### 3.9.1 Bernoulli 分布  
- **段落摘要**：  
- **关键字**：  
### 3.9.2 Multinoulli 分布  
- **段落摘要**：  
- **关键字**：  
### 3.9.3 高斯分布  
- **段落摘要**：  
- **关键字**：  
### 3.9.4 指数与 Laplace 分布  
- **段落摘要**：  
- **关键字**：  
### 3.9.5 Dirac 与经验分布  
- **段落摘要**：  
- **关键字**：  
### 3.9.6 分布混合  
- **段落摘要**：  
- **关键字**：  
## 3.10 常用函数性质  
- **段落摘要**：  
- **关键字**：  
## 3.11 贝叶斯规则  
- **段落摘要**：  
- **关键字**：  
## 3.12 连续型变量的技术细节  
- **段落摘要**：  
- **关键字**：  
## 3.13 信息论  
- **段落摘要**：  
- **关键字**：  
## 3.14 结构化概率模型  
- **段落摘要**：  
- **关键字**：  


---

# 第4章 数值计算

## 4.1 上溢与下溢  
- **段落摘要**：  
- **关键字**：  
## 4.2 病态条件  
- **段落摘要**：  
- **关键字**：  
## 4.3 基于梯度的优化方法  
### 4.3.1 Jacobi 与 Hessian 矩阵  
- **段落摘要**：  
- **关键字**：  
## 4.4 约束优化  
- **段落摘要**：  
- **关键字**：  
## 4.5 实例：线性最小二乘  
- **段落摘要**：  
- **关键字**：  


---

# 第5章 机器学习基础

## 5.1 学习算法概念（T, P, E）  
- **段落摘要**：  
- **关键字**：  
## 5.2 容量、过拟合与欠拟合  
- **段落摘要**：  
- **关键字**：  
## 5.3 超参数与验证集  
- **段落摘要**：  
- **关键字**：  
## 5.4 估计、偏差与方差  
- **段落摘要**：  
- **关键字**：  
## 5.5 最大似然估计  
- **段落摘要**：  
- **关键字**：  
## 5.6 贝叶斯统计与 MAP  
- **段落摘要**：  
- **关键字**：  
## 5.7 监督学习算法  
- **段落摘要**：  
- **关键字**：  
## 5.8 无监督学习算法  
- **段落摘要**：  
- **关键字**：  
## 5.9 随机梯度下降  
- **段落摘要**：  
- **关键字**：  
## 5.10 构建 ML 算法  
- **段落摘要**：  
- **关键字**：  
## 5.11 深度学习面临的挑战  
- **段落摘要**：  
- **关键字**：  


---

# 第6章 深度前馈网络

## 6.1 实例：学习 XOR  
- **段落摘要**：  
- **关键字**：  
## 6.2 基于梯度的学习  
- **段落摘要**：  
- **关键字**：  
## 6.3 隐藏单元  
- **段落摘要**：  
- **关键字**：  
## 6.4 架构设计  
- **段落摘要**：  
- **关键字**：  
## 6.5 反向传播与微分算法  
- **段落摘要**：  
- **关键字**：  
## 6.6 历史回顾  
- **段落摘要**：  
- **关键字**：  


---

# 第7章 深度学习中的正则化

## 7.1 参数范数惩罚  
- **段落摘要**：  
- **关键字**：  
## 7.2 约束形式范数惩罚  
- **段落摘要**：  
- **关键字**：  
## 7.3 正则化与欠约束问题  
- **段落摘要**：  
- **关键字**：  
## 7.4 数据集增强  
- **段落摘要**：  
- **关键字**：  
## 7.5 噪声鲁棒性  
- **段落摘要**：  
- **关键字**：  
## 7.6 半监督学习  
- **段落摘要**：  
- **关键字**：  
## 7.7 多任务学习  
- **段落摘要**：  
- **关键字**：  
## 7.8 提前终止  
- **段落摘要**：  
- **关键字**：  
## 7.9 参数绑定与共享（含卷积）  
- **段落摘要**：  
- **关键字**：  
## 7.10 稀疏表示  
- **段落摘要**：  
- **关键字**：  
## 7.11 Bagging 与集成方法  
- **段落摘要**：  
- **关键字**：  
## 7.12 Dropout  
- **段落摘要**：  
- **关键字**：  
## 7.13 对抗训练  
- **段落摘要**：  
- **关键字**：  
## 7.14 切面距离与流形正切分类器  
- **段落摘要**：  
- **关键字**：  


---

# 第8章 深度模型中的优化

## 8.1 学习 vs 纯优化  
- **段落摘要**：  
- **关键字**：  
## 8.2 优化挑战（病态、鞍点等）  
- **段落摘要**：  
- **关键字**：  
## 8.3 基本算法：SGD、动量、Nesterov  
- **段落摘要**：  
- **关键字**：  
## 8.4 参数初始化  
- **段落摘要**：  
- **关键字**：  
## 8.5 自适应学习率（AdaGrad/RMSProp/Adam）  
- **段落摘要**：  
- **关键字**：  
## 8.6 二阶近似：牛顿、共轭梯度、BFGS  
- **段落摘要**：  
- **关键字**：  
## 8.7 优化策略与元算法（批标准化、课程学习）  
- **段落摘要**：  
- **关键字**：  


---

# 第9章 卷积网络

## 9.1 卷积运算  
- **段落摘要**：  
- **关键字**：  
## 9.2 动机  
- **段落摘要**：  
- **关键字**：  
## 9.3 池化  
- **段落摘要**：  
- **关键字**：  
## 9.4 无限强先验  
- **段落摘要**：  
- **关键字**：  
## 9.5 卷积变体  
- **段落摘要**：  
- **关键字**：  
## 9.6 结构化输出  
- **段落摘要**：  
- **关键字**：  
## 9.7 数据类型  
- **段落摘要**：  
- **关键字**：  
## 9.8 高效卷积实现  
- **段落摘要**：  
- **关键字**：  
## 9.9 随机或无监督特征  
- **段落摘要**：  
- **关键字**：  
## 9.10 神经科学基础  
- **段落摘要**：  
- **关键字**：  
## 9.11 历史回顾  
- **段落摘要**：  
- **关键字**：  


---

# 第10章 序列建模：循环和递归网络

## 10.1 展开计算图  
- **段落摘要**：  
- **关键字**：  
## 10.2 循环神经网络  
- **段落摘要**：  
- **关键字**：  
## 10.3 双向 RNN  
- **段落摘要**：  
- **关键字**：  
## 10.4 编码-解码架构  
- **段落摘要**：  
- **关键字**：  
## 10.5 深度循环网络  
- **段落摘要**：  
- **关键字**：  
## 10.6 递归神经网络  
- **段落摘要**：  
- **关键字**：  
## 10.7 长期依赖挑战  
- **段落摘要**：  
- **关键字**：  
## 10.8 回声状态网络  
- **段落摘要**：  
- **关键字**：  
## 10.9 多时间尺度策略  
- **段落摘要**：  
- **关键字**：  
## 10.10 LSTM与门控RNN  
- **段落摘要**：  
- **关键字**：  
## 10.11 优化长期依赖  
- **段落摘要**：  
- **关键字**：  
## 10.12 外显记忆  
- **段落摘要**：  
- **关键字**：  


---

# 第11章 实践方法论

## 11.1 性能度量  
- **段落摘要**：  
- **关键字**：  
## 11.2 基准模型  
- **段落摘要**：  
- **关键字**：  
## 11.3 是否需更多数据  
- **段落摘要**：  
- **关键字**：  
## 11.4 超参数搜索（手动/自动/随机/贝叶斯）  
- **段落摘要**：  
- **关键字**：  
## 11.5 调试策略  
- **段落摘要**：  
- **关键字**：  
## 11.6 多位数字识别示例  
- **段落摘要**：  
- **关键字**：  


---

# 第12章 应用

## 12.1 大规模深度学习  
- **段落摘要**：  
- **关键字**：  
### 12.1.1 CPU 实现  
- **段落摘要**：  
- **关键字**：  
### 12.1.2 GPU 实现  
- **段落摘要**：  
- **关键字**：  
### 12.1.3 分布式实现  
- **段落摘要**：  
- **关键字**：  
### 12.1.4 模型压缩  
- **段落摘要**：  
- **关键字**：  
### 12.1.5 动态结构与专用硬件  
- **段落摘要**：  
- **关键字**：  

## 12.2 计算机视觉  
- **段落摘要**：  
- **关键字**：  

## 12.3 语音识别  
- **段落摘要**：  
- **关键字**：  

## 12.4 自然语言处理  
- **段落摘要**：  
- **关键字**：  

## 12.5 其他应用（推荐、问答等）  
- **段落摘要**：  
- **关键字**：  


---

# 第13章 线性因子模型

## 13.1 概率 PCA 与因子分析  
- **段落摘要**：  
- **关键字**：  
## 13.2 独立成分分析  
- **段落摘要**：  
- **关键字**：  
## 13.3 慢特征分析  
- **段落摘要**：  
- **关键字**：  
## 13.4 稀疏编码  
- **段落摘要**：  
- **关键字**：  
## 13.5 PCA 的流形解释  
- **段落摘要**：  
- **关键字**：  


---

# 第14章 自编码器

## 14.1 欠完备自编码器  
- **段落摘要**：  
- **关键字**：  
## 14.2 正则自编码器  
- **段落摘要**：  
- **关键字**：  
### 14.2.1 稀疏自编码器  
- **段落摘要**：  
- **关键字**：  
### 14.2.2 去噪自编码器  
- **段落摘要**：  
- **关键字**：  
### 14.2.3 惩罚导数正则  
- **段落摘要**：  
- **关键字**：  
## 14.3 表示能力、层大小与深度  
- **段落摘要**：  
- **关键字**：  
## 14.4 随机编码器与解码器  
- **段落摘要**：  
- **关键字**：  
## 14.5 去噪自编码器详解  
- **段落摘要**：  
- **关键字**：  
## 14.6 流形学习  
- **段落摘要**：  
- **关键字**：  
## 14.7 收缩自编码器  
- **段落摘要**：  
- **关键字**：  
## 14.8 预测稀疏分解  
- **段落摘要**：  
- **关键字**：  
## 14.9 自编码器应用  
- **段落摘要**：  
- **关键字**：  


---

# 第15章 表示学习

## 15.1 贪心逐层无监督预训练  
- **段落摘要**：  
- **关键字**：  
## 15.2 迁移学习与领域自适应  
- **段落摘要**：  
- **关键字**：  
## 15.3 半监督因果解释  
- **段落摘要**：  
- **关键字**：  
## 15.4 分布式表示  
- **段落摘要**：  
- **关键字**：  
## 15.5 深度带来的指数增益  
- **段落摘要**：  
- **关键字**：  
## 15.6 潜在因果线索  
- **段落摘要**：  
- **关键字**：  


---

# 第16章 结构化概率模型

## 16.1 非结构化建模挑战  
- **段落摘要**：  
- **关键字**：  
## 16.2 图模型表示  
- **段落摘要**：  
- **关键字**：  
### 16.2.1 有向模型  
- **段落摘要**：  
- **关键字**：  
### 16.2.2 无向模型  
- **段落摘要**：  
- **关键字**：  
### 16.2.3 配分函数  
- **段落摘要**：  
- **关键字**：  
### 16.2.4 能量模型  
- **段落摘要**：  
- **关键字**：  
### 16.2.5 分离与 d-分离  
- **段落摘要**：  
- **关键字**：  
### 16.2.6 有向↔无向转换  
- **段落摘要**：  
- **关键字**：  
### 16.2.7 因子图  
- **段落摘要**：  
- **关键字**：  
## 16.3 从图模型采样  
- **段落摘要**：  
- **关键字**：  
## 16.4 结构化建模优势  
- **段落摘要**：  
- **关键字**：  
## 16.5 学习依赖关系  
- **段落摘要**：  
- **关键字**：  
## 16.6 推断与近似推断  
- **段落摘要**：  
- **关键字**：  
## 16.7 深度方法：RBM 示例  
- **段落摘要**：  
- **关键字**：  


---

# 第17章 蒙特卡罗方法

## 17.1 蒙特卡罗采样基础  
- **段落摘要**：  
- **关键字**：  
## 17.2 重要采样  
- **段落摘要**：  
- **关键字**：  
## 17.3 马尔可夫链蒙特卡罗  
- **段落摘要**：  
- **关键字**：  
## 17.4 Gibbs 采样  
- **段落摘要**：  
- **关键字**：  
## 17.5 混合挑战与回火、深度混合可能性  
- **段落摘要**：  
- **关键字**：  


---

# 第18章 直面配分函数

## 18.1 对数似然梯度  
- **段落摘要**：  
- **关键字**：  
## 18.2 随机最大似然与对比散度  
- **段落摘要**：  
- **关键字**：  
## 18.3 伪似然  
- **段落摘要**：  
- **关键字**：  
## 18.4 得分匹配与比率匹配  
- **段落摘要**：  
- **关键字**：  
## 18.5 去噪得分匹配  
- **段落摘要**：  
- **关键字**：  
## 18.6 噪声对比估计  
- **段落摘要**：  
- **关键字**：  
## 18.7 估计配分函数（退火重要采样、桥式采样）  
- **段落摘要**：  
- **关键字**：  


---

# 第19章 近似推断

## 19.1 把推断视作优化  
- **段落摘要**：  
- **关键字**：  
## 19.2 期望最大化  
- **段落摘要**：  
- **关键字**：  
## 19.3 MAP 推断与稀疏编码  
- **段落摘要**：  
- **关键字**：  
## 19.4 变分推断与变分学习  
- **段落摘要**：  
- **关键字**：  
## 19.5 学成近似推断（醒眠算法等）  
- **段落摘要**：  
- **关键字**：  


---

# 第20章 深度生成模型

## 20.1 玻尔兹曼机  
- **段落摘要**：  
- **关键字**：  
## 20.2 受限玻尔兹曼机  
- **段落摘要**：  
- **关键字**：  
## 20.3 深度信念网络  
- **段落摘要**：  
- **关键字**：  
## 20.4 深度玻尔兹曼机  
- **段落摘要**：  
- **关键字**：  
## 20.5 实值 RBM  
- **段落摘要**：  
- **关键字**：  
## 20.6 卷积玻尔兹曼机  
- **段落摘要**：  
- **关键字**：  
## 20.7 结构化/序列输出 RBM  
- **段落摘要**：  
- **关键字**：  
## 20.8 其他 RBM  
- **段落摘要**：  
- **关键字**：  
## 20.9 随机操作反向传播  
- **段落摘要**：  
- **关键字**：  
## 20.10 有向生成网络概览  
- **段落摘要**：  
- **关键字**：  
### 20.10.1 Sigmoid 信念网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.2 可微生成器网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.3 变分自编码器  
- **段落摘要**：  
- **关键字**：  
### 20.10.4 生成对抗网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.5 生成矩匹配网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.6 卷积生成网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.7 自回归网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.8 线性自回归网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.9 神经自回归网络  
- **段落摘要**：  
- **关键字**：  
### 20.10.10 NADE  
- **段落摘要**：  
- **关键字**：  
## 20.11 自编码器采样马尔可夫链  
- **段落摘要**：  
- **关键字**：  
## 20.12 生成随机网络（GSN）  
- **段落摘要**：  
- **关键字**：  
## 20.13 其他生成方案  
- **段落摘要**：  
- **关键字**：  
## 20.14 评估生成模型  
- **段落摘要**：  
- **关键字**：  
## 20.15 结论  
- **段落摘要**：  
- **关键字**：  